{
  "capabilities": [
    {
      "name": " I want to process data in (near) real time (without persisting it)",
      "description": "I want to process data in order to get immidate insights and there is no need to persist that data (at least not the raw data) for later processing.",
      "id": 0
    },
    {
      "name": " I want to persist and process data in (near) real time",
      "description": "I need to process real time data and at the same time I need to save the (raw) data for later processing.",
      "id": 1
    },
    {
      "name": "I want to save large amounts of structured (relational) data in a consistent way for further processing",
      "description": "I need to save large relational and structured data sets that can be mapped to a fixed structure and come with low veracity.",
      "id": 2
    },
    {
      "name": "I need to save large amounts of unstructured data which comes in many files.",
      "description": "I have data sources that produces many files with unstructured data and I need a way to cheaply and efficiently save this data.",
      "id": 3
    },
    {
      "name": "I need to save large files of unstructured content",
      "description": "I need to save large files of unstrucutured content (e.g. audio/video files).",
      "id": 4
    },
    {
      "name": "I want to add analyzable meta data to my unstructured content to allow enhanced exploration",
      "description": "I need to add meta data to files that go beyond created_at, author etc. E.g. custom attributes like responsibility, related content and the like.",
      "id": 5
    },
    {
      "name": "I need to save and access semi-structured content with changing schemas",
      "description": "I have semi-structured content (e.g. JSON/XML) and schemas that are not fixed and need a way to efficiently save and access that data.",
      "id": 6
    },
    {
      "name": "I need to efficiently cache simple key-value data",
      "description": "I need a cache that quickly saves and provides that that can be saved as a key-value-pair (e.g. repetetive API calls).",
      "id": 7
    },
    {
      "name": "I want to provide an asynchronous way for communication between components",
      "description": "Components should not directly communicate, but should use a broker that enables an asychronous communication.",
      "id": 8
    },
    {
      "name": "I need to process data right at the data source (Edge Processing)",
      "description": "Some data sets need to be processed before transfering it into the analtycal landscape (e.g. due to volumes/transfer rates or privacy compliance).",
      "id": 9
    },
    {
      "name": "I need to apply real time transformations to streaming data",
      "description": "I need to process real time data and apply certain transformations to the data.",
      "id": 10
    },
    {
      "name": "I need to monitor streaming data in order to discover certain patterns in real time",
      "description": "I need to monitor streaming data in order to discover certain patterns in real time",
      "id": 11
    },
    {
      "name": "I need to save and process data that represents mosly relations between entities (Graph data)",
      "description": "I have data sets that respresents graphs (nodes and relations) and need to apply graph algorithms to the data set.",
      "id": 12
    },
    {
      "name": "I need to model data in a flexible way that allows me to easily extend schemas without breaking downstream systems",
      "description": "I need a data model that allows me to model raw data in a strucuted way but is flexible enough to be extendedn in a not-breakable way",
      "id": 13
    },
    {
      "name": "I need a overarching structure to search for metadata in the entire data lake.",
      "description": "A way to search meta data and contens that spans over all components in the data lake",
      "id": 14
    },
    {
      "name": "I need a way to document data transformations (data lineage)",
      "description": "I need a way to document data transformations (data lineage)",
      "id": 15
    },
    {
      "name": "I need to run distributed queries across different data sources",
      "description": "I need to run (interactive( analytic queries against data sources of all sizes ranging from gigabytes to petabytes in my data lake.",
      "id": 16
    },
    {
      "name": "I need to scan and ingest large amounts of log data",
      "description": "I need to scan and ingest large amounts of log data",
      "id": 17
    },
    {
      "name": "I need a way to optimize raw data for big data processing",
      "description": "I need a way to optimize raw data for big data processing, e.g. make it smaller, typesafe or faster",
      "id": 18
    },
    {
      "name": "I want to save structured relational content in an operational context",
      "description": "I want to save structured relational content in an operational context",
      "id": 19
    },
    {
      "name": "I need a security structure that handles file rights in my data lake",
      "description": "I need a security structure that handles file rights in my data lake",
      "id": 20
    }
  ],
  "categories": [
    {
      "id": 0,
      "name": "Extraction",
      "description": "Components that help to extract data from source systems"
    },
    {
      "id": 1,
      "name": "Connect & Coordinate",
      "description": "Components that connect and coordinate different components."
    },
    {
      "id": 2,
      "name": "Persistence",
      "description": "Components that are able to persist data."
    },
    {
      "id": 3,
      "name": "Management & Administration",
      "description": "Components to stay on top of things and provide administrative capabilites."
    }
  ],
  "patterns": [
    {
      "name": "Massive Data Store",
      "description": "The data lake needs to save massive amounts of structured and/or unstructured data.",
      "id": 0
    },
    {
      "name": "Stream-oriented Data Lake",
      "description": "One important purpose is the processing of fast data",
      "id": 1
    },
    {
      "name": "Hybrid approach (Lampda architecture)",
      "description": "Use a massive data store and streaming comonents in order to provide best of both worlds",
      "id": 2
    },
    {
      "name": "Event-driven architecture",
      "description": "Use an event-driven strucutre in order to become more flexible.",
      "id": 3
    }
  ],
  "products": [
    {
      "name": "Hadoop (HDFS + Map Reduce)",
      "description": "",
      "id": 0
    },
    {
      "name": "MongoDB",
      "description": "",
      "id": 1
    },
    {
      "name": "ElasticSearch",
      "description": "",
      "id": 2
    },
    {
      "name": "Nifi",
      "description": "",
      "id": 3
    },
    {
      "name": "Apache Atlas",
      "description": "",
      "id": 4
    },
    {
      "name": "Apache Kafka",
      "description": "",
      "id": 5
    },
    {
      "name": "Alation",
      "description": "",
      "id": 6
    },
    {
      "name": "Redis",
      "description": "",
      "id": 7
    },
    {
      "name": "AWS S3",
      "description": "",
      "id": 8
    },
    {
      "name": "Azure Blob Storage",
      "description": "",
      "id": 9
    },
    {
      "name": "IBM Object Store",
      "description": "",
      "id": 10
    },
    {
      "name": "Apache Samza",
      "description": "",
      "id": 11
    },
    {
      "name": "Cassandra",
      "description": "",
      "id": 12
    },
    {
      "name": "AWS SimpleDB",
      "description": "",
      "id": 13
    },
    {
      "name": "Apache HBase",
      "description": "",
      "id": 14
    },
    {
      "name": "Neo4J",
      "description": "",
      "id": 15
    },
    {
      "name": "HyperGraph DB",
      "description": "",
      "id": 16
    },
    {
      "name": "Cloudera Hadoop",
      "description": "",
      "id": 17
    },
    {
      "name": "MapR Hadoop",
      "description": "",
      "id": 18
    },
    {
      "name": "Azure Event Hub",
      "description": "",
      "id": 19
    },
    {
      "name": "Aerospike",
      "description": "",
      "id": 20
    },
    {
      "name": "Apache Storm",
      "description": "",
      "id": 21
    },
    {
      "name": "Apache Spark",
      "description": "",
      "id": 22
    },
    {
      "name": "IBM DB2",
      "description": "",
      "id": 23
    },
    {
      "name": "SAP Hana",
      "description": "",
      "id": 24
    },
    {
      "name": "Oracle DWH",
      "description": "",
      "id": 25
    },
    {
      "name": "Apache Flume",
      "description": "",
      "id": 26
    },
    {
      "name": "AWS Kinesis",
      "description": "",
      "id": 27
    },
    {
      "name": "Presto",
      "description": "",
      "id": 28
    },
    {
      "name": "Teradata",
      "description": "",
      "id": 29
    },
    {
      "name": "IBM Streams",
      "description": "",
      "id": 30
    },
    {
      "name": "AWS Redshift",
      "description": "",
      "id": 31
    },
    {
      "name": "LogStash",
      "description": "",
      "id": 32
    },
    {
      "name": "Avro",
      "description": "",
      "id": 33
    },
    {
      "name": "Parquet",
      "description": "",
      "id": 34
    },
    {
      "name": "MySQL",
      "description": "",
      "id": 35
    },
    {
      "name": "PostgreSQL",
      "description": "",
      "id": 36
    },
    {
      "name": "ZeroMQ",
      "description": "",
      "id": 37
    },
    {
      "name": "NanoMSG",
      "description": "",
      "id": 38
    },
    {
      "name": "Informatica Data Catalog",
      "description": "",
      "id": 39
    },
    {
      "name": "Apache ORC",
      "description": "",
      "id": 40
    },
    {
      "name": "DataVault",
      "description": "",
      "id": 41
    },
    {
      "name": "Apache Druid",
      "description": "",
      "id": 42
    },
    {
      "name": "Apache Ranger",
      "description": "",
      "id": 43
    }
  ],
  "systems": [
    {
      "name": "Distributed File System",
      "description": "A distributed file system saves files on many machines and allows horicontal scaling.",
      "categories": [
        2
      ],
      "products": [
        0,
        17,
        18
      ],
      "capabilities": [
        3,
        4
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
        {
          "id": 1,
          "name": "BLOB Storage"
        }
      ],
      "id": 0
    },
    {
      "name": "BLOB Storage",
      "description": "A Binary Large OBject (BLOB) is a collection of binary data stored as a single entity in a database management system.Blobs are typically images, audio or other multimedia objects, though sometimes binary executable code is stored as a blob.",
      "categories": [
        2
      ],
      "products": [
        8,
        9,
        10
      ],
      "capabilities": [
        3,
        4,
        5
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
        {
          "id": 0,
          "name": "Distributed File System"
        }
      ],
      "id": 1
    },
    {
      "name": "NoSQL-Database: Document-Store ",
      "description": "A document-oriented database, or document store, is a computer program designed for storing, retrieving and managing document-oriented information, also known as semi-structured data. Document-oriented databases are one of the main categories of NoSQL databases, and the popularity of the term \"document-oriented database\" has grown with the use of the term NoSQL itself.",
      "categories": [
        2
      ],
      "products": [
        1,
        2,
        14
      ],
      "capabilities": [
        4,
        6,
        13
      ],
      "patterns": [
        0
      ],
      "substitutions": [
        {
          "id": 4,
          "name": "No-SQL-Databases: Key-Value-Stores"
        },
        {
          "id": 5,
          "name": "No-SQL-Databases: Wide-Column-Stores"
        },
        {
          "id": 14,
          "name": "Relational Database"
        }
      ],
      "id": 2
    },
    {
      "name": "No-SQL-Database: Graph-Database",
      "description": "In computing, a graph database is a database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data. A key concept of the system is the graph. The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes.",
      "categories": [
        2
      ],
      "products": [
        15,
        16
      ],
      "capabilities": [
        4,
        12
      ],
      "patterns": [
        0
      ],
      "substitutions": [
        {
          "id": 2,
          "name": "NoSQL-Database: Document-Store "
        },
        {
          "id": 5,
          "name": "No-SQL-Databases: Wide-Column-Stores"
        },
        {
          "id": 14,
          "name": "Relational Database"
        }
      ],
      "id": 3
    },
    {
      "name": "No-SQL-Databases: Key-Value-Stores",
      "description": "A key–value database, or key–value store, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, a data structure more commonly known today as a dictionary or hash. Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to quickly find the data within the database.",
      "categories": [
        2
      ],
      "products": [
        7,
        20
      ],
      "capabilities": [
        4,
        7
      ],
      "patterns": [
        0
      ],
      "substitutions": [
        {
          "id": 2,
          "name": "NoSQL-Database: Document-Store "
        }
      ],
      "id": 4
    },
    {
      "name": "No-SQL-Databases: Wide-Column-Stores",
      "description": "A wide column store is a type of NoSQL database. It uses tables, rows, and columns, but unlike a relational database, the names and format of the columns can vary from row to row in the same table. A wide column store can be interpreted as a two-dimensional key-value store.",
      "categories": [
        2
      ],
      "products": [
        12,
        13
      ],
      "capabilities": [
        4,
        6,
        13
      ],
      "patterns": [
        0
      ],
      "substitutions": [
        {
          "id": 2,
          "name": "NoSQL-Database: Document-Store "
        },
        {
          "id": 14,
          "name": "Relational Database"
        }
      ],
      "id": 5
    },
    {
      "name": "Data Catalog",
      "description": "A data catalog is a completely organized service that enables users to explore their required data sources and understand the data sources explored, and at the same time assist organizations to achieve more value from their present investments. A user has to know the location of a data source to connect to the data.",
      "categories": [
        3
      ],
      "products": [
        4,
        6,
        39
      ],
      "capabilities": [
        5,
        14,
        15
      ],
      "patterns": [
        0,
        2,
        3
      ],
      "substitutions": [
      ],
      "id": 6
    },
    {
      "name": "Distirbuted Query Engine",
      "description": "Distributed queries involve data that's stored on another server, be it on a server in the same room or on a machine a half a world away. ",
      "categories": [
        1
      ],
      "products": [
        28
      ],
      "capabilities": [
        16
      ],
      "patterns": [
        0
      ],
      "substitutions": [
      ],
      "id": 7
    },
    {
      "name": "Ingestion Engine",
      "description": "An ingestion engine allows to extract and transform data and load it into downstream systems.",
      "categories": [
        0
      ],
      "products": [
        21,
        32
      ],
      "capabilities": [
        17,
        18
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
      ],
      "id": 8
    },
    {
      "name": "Edge Processing Engine",
      "description": "Edge computing is a distributed computing paradigm which brings computation and data storage closer to the location where it is needed, to improve response times and save bandwidth.",
      "categories": [
        0
      ],
      "products": [
        3
      ],
      "capabilities": [
        9
      ],
      "patterns": [
        1,
        2,
        3
      ],
      "substitutions": [
        {
          "id": 12,
          "name": "Stream Processing Engine"
        }
      ],
      "id": 9
    },
    {
      "name": "Message queue",
      "description": "In computer science, message queues and mailboxes are software-engineering components used for inter-process communication, or for inter-thread communication within the same process. They use a queue for messaging – the passing of control or of content. Group communication systems provide similar kinds of functionality.",
      "categories": [
        1
      ],
      "products": [
        37,
        38
      ],
      "capabilities": [
        8
      ],
      "patterns": [
        1,
        3
      ],
      "substitutions": [
        {
          "id": 11,
          "name": "Message Broker/Log"
        },
        {
          "id": 12,
          "name": "Stream Processing Engine"
        }
      ],
      "id": 10
    },
    {
      "name": "Message Broker/Log",
      "description": "Allows asynchronous commincation by provideng a publish-subscribe pattern for various components",
      "categories": [
        1
      ],
      "products": [
        5,
        11,
        27,
        30
      ],
      "capabilities": [
        0,
        1,
        8
      ],
      "patterns": [
        3
      ],
      "substitutions": [
        {
          "id": 10,
          "name": "Message queue"
        },
        {
          "id": 12,
          "name": "Stream Processing Engine"
        }
      ],
      "id": 11
    },
    {
      "name": "Stream Processing Engine",
      "description": "Stream processing is a computer programming paradigm, equivalent to dataflow programming, event stream processing, and reactive programming, that allows some applications to more easily exploit a limited form of parallel processing.",
      "categories": [
      ],
      "products": [
        21,
        22,
        27,
        42
      ],
      "capabilities": [
        0,
        1,
        10,
        11
      ],
      "patterns": [
        1,
        2
      ],
      "substitutions": [
        {
          "id": 8,
          "name": "Ingestion Engine"
        },
        {
          "id": 10,
          "name": "Message queue"
        },
        {
          "id": 11,
          "name": "Message Broker/Log"
        }
      ],
      "id": 12
    },
    {
      "name": "Data Warehouse",
      "description": "A data warehouse is a subject-oriented, integrated, time-variant and non-volatile collection of data in support of management's decision making process.",
      "categories": [
        2
      ],
      "products": [
        23,
        24,
        25,
        29,
        31
      ],
      "capabilities": [
        2
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
        {
          "id": 0,
          "name": "Distributed File System"
        },
        {
          "id": 2,
          "name": "NoSQL-Database: Document-Store "
        }
      ],
      "id": 13
    },
    {
      "name": "Relational Database",
      "description": "A relational database is a digital database based on the relational model of data, as proposed by E. F. Codd in 1970. A software system used to maintain relational databases is a relational database management system (RDBMS).",
      "categories": [
        2
      ],
      "products": [
        35,
        36
      ],
      "capabilities": [
        19
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
        {
          "id": 2,
          "name": "NoSQL-Database: Document-Store "
        },
        {
          "id": 5,
          "name": "No-SQL-Databases: Wide-Column-Stores"
        },
        {
          "id": 13,
          "name": "Data Warehouse"
        }
      ],
      "id": 14
    },
    {
      "name": "Data Vault Modelling",
      "description": "Data vault modeling is a database modeling method that is designed to provide long-term historical storage of data coming in from multiple operational systems. It is also a method of looking at historical data that deals with issues such as auditing, tracing of data, loading speed and resilience to change as well as emphasizing the need to trace where all the data in the database came from.",
      "categories": [
        2
      ],
      "products": [
        23,
        24,
        25,
        29,
        31,
        35,
        36
      ],
      "capabilities": [
        2,
        6,
        13
      ],
      "patterns": [
        0,
        2
      ],
      "substitutions": [
      ],
      "id": 15
    },
    {
      "name": "Big Data Format",
      "description": "Big data formats are abstractions that can be applied to enrich raw data in order to compress it or enhance performance.",
      "categories": [
        2,
        3
      ],
      "products": [
        0,
        17,
        18
      ],
      "capabilities": [
        17,
        18
      ],
      "patterns": [
        0,
        1
      ],
      "substitutions": [
      ],
      "id": 16
    },
    {
      "name": "Big Data Security Management",
      "description": "A tool to establish a comprehensive security strategy spanning over various tools.",
      "categories": [
        3
      ],
      "products": [
        43
      ],
      "capabilities": [
        20
      ],
      "patterns": [
        0
      ],
      "substitutions": [
      ],
      "id": 17
    }
  ]
}
